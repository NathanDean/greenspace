{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88951a8c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5cce35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d30153f",
   "metadata": {},
   "source": [
    "# Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "64a758e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c481cda7",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "09213324",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"datasets/5_split/df_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4acae633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.copy()\n",
    "sample_df = df.groupby('fold_id_python').sample(n = 20, random_state = 42)\n",
    "sample_df = sample_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cdd31d",
   "metadata": {},
   "source": [
    "# Separate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7f7fedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dependent variables\n",
    "# labels = df.pop('very_good_health')\n",
    "\n",
    "# # CV folds\n",
    "# fold_ids = df.pop(\"fold_id_python\")\n",
    "# folds = np.unique(fold_ids)\n",
    "\n",
    "# # Independent variables\n",
    "# features = df.drop(columns = [\"fold_id_r\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "40accc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent variables\n",
    "labels = sample_df.pop('very_good_health')\n",
    "\n",
    "# CV folds\n",
    "fold_ids = sample_df.pop(\"fold_id_python\")\n",
    "folds = np.unique(fold_ids)\n",
    "\n",
    "# Independent variables\n",
    "features = sample_df.drop(columns = [\"fold_id_r\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f104f7e",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf81de3",
   "metadata": {},
   "source": [
    "## Get random hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4146450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_hyperparameters():\n",
    "    no_of_layers = np.random.randint(1, 10)\n",
    "    no_of_nodes = []\n",
    "    for i in range(0, no_of_layers):\n",
    "        no_of_nodes.append(np.random.randint(10, 100))\n",
    "    learning_rate = np.random.uniform(0.0001, 0.01)\n",
    "    epochs = np.random.randint(20, 500)\n",
    "    patience = np.random.randint(5, 15)\n",
    "    return no_of_layers, no_of_nodes, learning_rate, epochs, patience\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4683c943",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8ded2bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train_features, no_of_layers, no_of_nodes, learning_rate):\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    normaliser = keras.layers.Normalization(axis = -1)\n",
    "    normaliser.adapt(np.array(train_features))\n",
    "    layers.append(normaliser)\n",
    "\n",
    "    for layer_no in range(no_of_layers):\n",
    "        layers.append(keras.layers.Dense(no_of_nodes[layer_no], activation = \"relu\"))\n",
    "\n",
    "    layers.append(keras.layers.Dense(1))     # Single output for regression value\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        layers,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "        loss='mse'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfcfaeb",
   "metadata": {},
   "source": [
    "## Build early stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b12c3775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_early_stopper(patience):\n",
    "    early_stopper = keras.callbacks.EarlyStopping(\n",
    "        monitor = \"val_loss\",\n",
    "        patience = patience,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    return early_stopper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d08487",
   "metadata": {},
   "source": [
    "## Get evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d08d68f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_metrics(val_labels, predictions):\n",
    "    mae = mean_absolute_error(val_labels, predictions)\n",
    "    mse = mean_squared_error(val_labels, predictions)\n",
    "    r2 = r2_score(val_labels, predictions)\n",
    "    return mae, mse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e1cef0",
   "metadata": {},
   "source": [
    "## Get average score across cross-validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "644f1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_scores(cv_results):\n",
    "    mae_scores = []\n",
    "    mse_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    for result in cv_results:\n",
    "        mae_scores.append(result[\"mae\"])\n",
    "        mse_scores.append(result[\"mse\"])\n",
    "        r2_scores.append(result[\"r2\"])\n",
    "\n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    avg_mse = np.mean(mse_scores)\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "\n",
    "    return avg_mae, avg_mse, avg_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91bcd3b",
   "metadata": {},
   "source": [
    "## Get optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3c9b04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_hyperparameters(hp_combinations, cv_results):\n",
    "    hp_combination_scores = []\n",
    "    for i in range(len(hp_combinations)):\n",
    "        current_hp_combination_results = [result for result in cv_results if result[\"hp_combination\"] == i]\n",
    "        mae, mse, r2 = get_avg_scores(current_hp_combination_results)\n",
    "        hp_combination_scores.append(mse)\n",
    "    optimal_combination = np.argmin(hp_combination_scores)\n",
    "    optimal_hps = hp_combinations[optimal_combination]\n",
    "    return optimal_hps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69935674",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290ec8d",
   "metadata": {},
   "source": [
    "## Initialise HP and results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6831bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_combinations = []\n",
    "cv_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8cfe58",
   "metadata": {},
   "source": [
    "##  Inner loop for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "df42911f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --- Training model 0 on fold 0 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      " --- Training model 0 on fold 1 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\n",
      " --- Training model 0 on fold 2 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " --- Training model 0 on fold 3 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " --- Training model 0 on fold 4 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " --- Training model 0 on fold 5 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\n",
      " --- Training model 0 on fold 6 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " --- Training model 0 on fold 7 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\n",
      " --- Training model 0 on fold 8 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " --- Training model 0 on fold 9 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " --- Training model 1 on fold 0 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      " --- Training model 1 on fold 1 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      " --- Training model 1 on fold 2 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      " --- Training model 1 on fold 3 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      " --- Training model 1 on fold 4 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      " --- Training model 1 on fold 5 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      " --- Training model 1 on fold 6 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      " --- Training model 1 on fold 7 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\n",
      " --- Training model 1 on fold 8 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      " --- Training model 1 on fold 9 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\n",
      " --- Training model 2 on fold 0 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      " --- Training model 2 on fold 1 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      " --- Training model 2 on fold 2 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      " --- Training model 2 on fold 3 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\n",
      " --- Training model 2 on fold 4 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      " --- Training model 2 on fold 5 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      " --- Training model 2 on fold 6 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      " --- Training model 2 on fold 7 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      " --- Training model 2 on fold 8 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      " --- Training model 2 on fold 9 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\n",
      " --- Training model 3 on fold 0 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\n",
      " --- Training model 3 on fold 1 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\n",
      " --- Training model 3 on fold 2 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " --- Training model 3 on fold 3 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\n",
      " --- Training model 3 on fold 4 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      " --- Training model 3 on fold 5 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " --- Training model 3 on fold 6 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      " --- Training model 3 on fold 7 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " --- Training model 3 on fold 8 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " --- Training model 3 on fold 9 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\n",
      " --- Training model 4 on fold 0 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\n",
      " --- Training model 4 on fold 1 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\n",
      " --- Training model 4 on fold 2 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\n",
      " --- Training model 4 on fold 3 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\n",
      " --- Training model 4 on fold 4 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\n",
      " --- Training model 4 on fold 5 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      " --- Training model 4 on fold 6 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\n",
      " --- Training model 4 on fold 7 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\n",
      " --- Training model 4 on fold 8 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\n",
      " --- Training model 4 on fold 9 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\n",
      " --- Training model 5 on fold 0 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      " --- Training model 5 on fold 1 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\n",
      " --- Training model 5 on fold 2 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\n",
      " --- Training model 5 on fold 3 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      " --- Training model 5 on fold 4 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\n",
      " --- Training model 5 on fold 5 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      " --- Training model 5 on fold 6 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      " --- Training model 5 on fold 7 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\n",
      " --- Training model 5 on fold 8 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\n",
      " --- Training model 5 on fold 9 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\n",
      " --- Training model 6 on fold 0 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\n",
      " --- Training model 6 on fold 1 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      " --- Training model 6 on fold 2 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      " --- Training model 6 on fold 3 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\n",
      " --- Training model 6 on fold 4 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      " --- Training model 6 on fold 5 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      " --- Training model 6 on fold 6 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      " --- Training model 6 on fold 7 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      " --- Training model 6 on fold 8 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      " --- Training model 6 on fold 9 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\n",
      " --- Training model 7 on fold 0 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\n",
      " --- Training model 7 on fold 1 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      " --- Training model 7 on fold 2 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\n",
      " --- Training model 7 on fold 3 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      " --- Training model 7 on fold 4 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\n",
      " --- Training model 7 on fold 5 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\n",
      " --- Training model 7 on fold 6 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\n",
      " --- Training model 7 on fold 7 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      " --- Training model 7 on fold 8 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      " --- Training model 7 on fold 9 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      " --- Training model 8 on fold 0 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\n",
      " --- Training model 8 on fold 1 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\n",
      " --- Training model 8 on fold 2 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\n",
      " --- Training model 8 on fold 3 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      " --- Training model 8 on fold 4 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\n",
      " --- Training model 8 on fold 5 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\n",
      " --- Training model 8 on fold 6 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      " --- Training model 8 on fold 7 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\n",
      " --- Training model 8 on fold 8 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\n",
      " --- Training model 8 on fold 9 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\n",
      " --- Training model 9 on fold 0 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      " --- Training model 9 on fold 1 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\n",
      " --- Training model 9 on fold 2 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\n",
      " --- Training model 9 on fold 3 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\n",
      " --- Training model 9 on fold 4 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\n",
      " --- Training model 9 on fold 5 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\n",
      " --- Training model 9 on fold 6 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      " --- Training model 9 on fold 7 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      " --- Training model 9 on fold 8 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\n",
      " --- Training model 9 on fold 9 ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    # Get hyperparameters\n",
    "    no_of_layers, no_of_nodes, learning_rate, epochs, patience = get_random_hyperparameters()\n",
    "    current_hps = {\n",
    "        \"no_of_layers\": no_of_layers,\n",
    "        \"no_of_nodes\": no_of_nodes,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"epochs\": epochs,\n",
    "        \"patience\": patience\n",
    "    }\n",
    "    hp_combinations.append(current_hps)\n",
    "\n",
    "    # Inner cross-validation\n",
    "    for fold in folds:\n",
    "        print(f\"\\n --- Training model {i} on fold {fold} ---\")\n",
    "\n",
    "        # Get training and validation sets from inner fold ids\n",
    "        is_in_validation_set = fold_ids == fold\n",
    "        is_in_training_set = ~is_in_validation_set\n",
    "        train_features = features.loc[is_in_training_set]\n",
    "        train_labels = labels.loc[is_in_training_set]\n",
    "        val_features = features.loc[is_in_validation_set]\n",
    "        val_labels = labels.loc[is_in_validation_set]\n",
    "\n",
    "        # Build model\n",
    "        model = build_model(train_features, no_of_layers, no_of_nodes, learning_rate)\n",
    "        early_stopper = build_early_stopper(patience)\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(\n",
    "            train_features,\n",
    "            train_labels,\n",
    "            epochs = epochs,\n",
    "            validation_split = 0.2,     # Research whether I should use val_data for this, or whether that would lead to data leakage\n",
    "            callbacks = [early_stopper],\n",
    "            verbose = 0\n",
    "        )\n",
    "\n",
    "        # Get predictions using fitted model\n",
    "        predictions = model.predict(val_features).flatten()\n",
    "\n",
    "        # Get accuracy scores\n",
    "        mae, mse, r2 = get_evaluation_metrics(val_labels, predictions)\n",
    "\n",
    "        # Add scores for current fold to results\n",
    "        cv_results.append({\n",
    "            \"hp_combination\": i,\n",
    "            \"fold\": fold,\n",
    "            \"hps\": current_hps,\n",
    "            \"mae\": mae,\n",
    "            \"mse\": mse,\n",
    "            \"r2\": r2\n",
    "        })\n",
    "\n",
    "optimal_hps = get_optimal_hyperparameters(hp_combinations, cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf890d",
   "metadata": {},
   "source": [
    "## Get optimal HPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6b905cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_of_layers': 8,\n",
       " 'no_of_nodes': [87, 96, 71, 49, 94, 89, 91, 62],\n",
       " 'learning_rate': 0.005908836540072098,\n",
       " 'epochs': 236,\n",
       " 'patience': 13}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_optimal_hyperparameters(hp_combinations, cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e6d6ed",
   "metadata": {},
   "source": [
    "## Outer loop for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4e6c5660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fold in outer_folds:\n",
    "#     print(f\"\\n --- Training on fold {fold} ---\")\n",
    "\n",
    "#     # Get training and validation sets from inner fold ids\n",
    "#     is_in_validation_set = fold_ids == fold\n",
    "#     is_in_training_set = ~is_in_validation_set\n",
    "#     train_features = features.loc[is_in_training_set]\n",
    "#     train_labels = labels.loc[is_in_training_set]\n",
    "#     val_features = features.loc[is_in_validation_set]\n",
    "#     val_labels = labels.loc[is_in_validation_set]\n",
    "\n",
    "#     # Build model\n",
    "#     model = build_model(train_features, no_of_layers, no_of_nodes, learning_rate)\n",
    "#     early_stopper = build_early_stopper(patience)\n",
    "\n",
    "#     # Fit model\n",
    "#     model.fit(\n",
    "#         train_features,\n",
    "#         train_labels,\n",
    "#         epochs = epochs,\n",
    "#         validation_split = 0.2,     # Research whether I should use val_data for this, or whether that would lead to data leakage\n",
    "#         callbacks = [early_stopper],\n",
    "#         verbose = 0\n",
    "#     )\n",
    "\n",
    "#     # Get predictions using fitted model\n",
    "#     predictions = model.predict(val_features).flatten()\n",
    "\n",
    "#     # Get accuracy scores\n",
    "#     mae, mse, r2 = get_evaluation_metrics(val_labels, predictions)\n",
    "\n",
    "#     # Add scores for current fold to results\n",
    "#     cv_results.append({\n",
    "#         \"hp_combination\": i,\n",
    "#         \"fold\": fold,\n",
    "#         \"hps\": current_hps,\n",
    "#         \"mae\": mae,\n",
    "#         \"mse\": mse,\n",
    "#         \"r2\": r2\n",
    "#     })\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
